{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Install With `pip`\n",
    "```bash\n",
    "# requirements\n",
    "pip install pandas pyarrow \n",
    "\n",
    "# install dialect MySQL, Postgres\n",
    "pip install sqlalchemy pymysql psycopg2-binary\n",
    "# install dialect Veritca\n",
    "pip install git+https://github.com/attapon-th/sqlalchemy-vertica-python.git@latest\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class DBUtil\n",
    "\n",
    "- `has_tables`\n",
    "- `list_tables`\n",
    "- `get_columns` \n",
    "- `get_primarykeys`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy as sa\n",
    "from sqlalchemy.engine.interfaces import ReflectedColumn, ReflectedPrimaryKeyConstraint\n",
    "from sqlalchemy import Engine\n",
    "from typing import List, Any\n",
    "\n",
    "class DBUtil:\n",
    "    def __init__(self, engine: Engine, schema_or_dbname: str) -> None:\n",
    "        self.engine: Engine = engine\n",
    "        self.schema: str  = schema_or_dbname\n",
    "        self.conn = engine.connect()\n",
    "        self.closed: bool = True\n",
    "\n",
    "    def execute(self, sql: str, parameters: Any = None):\n",
    "        self.check_connect()\n",
    "        return self.conn.execute(sa.text(sql), parameters)\n",
    "\n",
    "    def close(self):\n",
    "        self.closed = True\n",
    "        self.conn.close()\n",
    "        self.engine.dispose()\n",
    "\n",
    "    def check_connect(self):\n",
    "        if self.closed:\n",
    "            self.conn = self.engine.connect()\n",
    "            self.closed = False\n",
    "\n",
    "    def has_tables(self, table: str) -> bool:\n",
    "        self.check_connect()\n",
    "        return self.conn.dialect.has_table(self.conn, table, schema=self.schema)\n",
    "\n",
    "    def list_tables(self) -> List[str]:\n",
    "        self.check_connect()\n",
    "        return self.conn.dialect.get_table_names(self.conn, self.schema)\n",
    "\n",
    "    def get_columns(self, table: str) -> list[ReflectedColumn]:\n",
    "        self.check_connect()\n",
    "        return self.conn.dialect.get_columns(self.conn, table, self.schema)\n",
    "    \n",
    "    def get_column_names(self, table: str) -> list[str]:\n",
    "        self.check_connect()\n",
    "        return [c[\"name\"] for c in self.get_columns(table)]\n",
    "\n",
    "    def get_primarykeys(self, table: str) -> list[str]:\n",
    "        pk_cons: ReflectedPrimaryKeyConstraint = self.conn.dialect.get_pk_constraint(conn, table, self.schema)\n",
    "        has_pk_constraint: bool = isinstance(pk_cons, dict) and \"constrained_columns\" in pk_cons and len(pk_cons[\"constrained_columns\"]) > 0\n",
    "        if has_pk_constraint:\n",
    "            return pk_cons[\"constrained_columns\"]\n",
    "\n",
    "        columns: list[ReflectedColumn] = self.conn.dialect.get_columns(self.conn, table, schema=self.schema)\n",
    "        return [c[\"name\"] for c in columns if \"primary_key\" in c and c[\"primary_key\"] is True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vertica Copy CSV File With `STDIN`\n",
    "\n",
    "### เงื่อนไข\n",
    "\n",
    "1. ต้องมี Table รองรับแล้ว(Not auto create table)\n",
    "2. request function helper\n",
    "   1. `get_columns`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy.engine import Engine\n",
    "from pandas import DataFrame\n",
    "from typing import Literal\n",
    "from typing import List, Any\n",
    "\n",
    "\n",
    "class VerticaCopy(DBUtil):\n",
    "    def __init__(self, engine: Engine, schema: str) -> None:\n",
    "        super().__init__(engine, schema)\n",
    "\n",
    "        self._from_input = \"STDIN\"\n",
    "        self._compression: Literal[\"BZIP\", \"GZIP\", \"\"] = \"\"\n",
    "        self._columns: list[str] = []\n",
    "\n",
    "    def input(self, filepath: str):\n",
    "        if filepath.upper() != \"STDIN\":\n",
    "            filepath = \"'\" + filepath + \"'\"\n",
    "        return self\n",
    "\n",
    "    def commpression(self, compression: Literal[\"BZIP\", \"GZIP\", \"\"]):\n",
    "        self._compression = compression\n",
    "        return self\n",
    "\n",
    "    def columns(self, columns: list[str]):\n",
    "        self._columns = columns\n",
    "        return self\n",
    "\n",
    "    def get_sql(self, table: str, reject_table: str | None = \"\") -> str:\n",
    "        self.check_connect()\n",
    "        schema: str = self.schema\n",
    "\n",
    "        colStr = \"\"\n",
    "        if len(self._columns) > 0:\n",
    "            colStr = f\"({', '.join(self._columns)})\"\n",
    "        sql: str = f\"COPY {schema}.{table}{colStr} FROM {self._from_input} {self._compression} PARSER fcsvparser()\"\n",
    "        if reject_table is not None:\n",
    "            sql += f\" REJECTED DATA AS TABLE {schema}.__REJECT_{table}\"\n",
    "        return sql\n",
    "\n",
    "    def copy(self, df: DataFrame, table: str) -> bool:\n",
    "        self.check_connect()\n",
    "        conn = self.engine.raw_connection().driver_connection\n",
    "        if conn is None:\n",
    "            return False\n",
    "        try:\n",
    "            src_columns: list[str] = df.columns.to_list()\n",
    "            tgt_column: list[str] = self.get_column_names(table)\n",
    "\n",
    "            # columns is src_columns intersect tgt_column\n",
    "            columns: list[str] = [a for a in src_columns if a in tgt_column]\n",
    "\n",
    "            sql: str = self.columns(columns).get_sql(table)\n",
    "\n",
    "            if not hasattr(conn, \"cursor\"):\n",
    "                print(\"cursor not support\")\n",
    "                return False\n",
    "\n",
    "            cur = conn.cursor()\n",
    "            if not hasattr(cur, \"copy\"):\n",
    "                print(\"copy not support\")\n",
    "                return False\n",
    "            cur.copy(sql, df.to_csv(index=False, escapechar='\"', quotechar='\"'))\n",
    "\n",
    "        except Exception as err:\n",
    "            conn.rollback()\n",
    "            print(err)\n",
    "\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy.engine import Engine\n",
    "from pandas import DataFrame\n",
    "from typing import Literal\n",
    "from typing import List, Any, Dict, Optional\n",
    "\n",
    "\n",
    "class VerticaMerge(DBUtil):\n",
    "    def __init__(self, engine: Engine, source_schema: str, source_table: str) -> None:\n",
    "        super().__init__(engine, source_schema)\n",
    "        self._targetdb: DBUtil\n",
    "\n",
    "        self._source_schema: str = source_schema\n",
    "        self._source_table: str = source_table\n",
    "\n",
    "        self._target_schema: str | None = None\n",
    "        self._target_table: str | None = None\n",
    "\n",
    "        self._on_columns: list[str] = []\n",
    "        self._insert_columns: list[str] = []\n",
    "        self._update_columns: list[str] = []\n",
    "\n",
    "    def source(self, schema: str, table: str):\n",
    "        self._source_schema = schema\n",
    "        self._source_table = table\n",
    "        return self\n",
    "\n",
    "    def target(self, schema: str, table: str):\n",
    "        self._target_schema = schema\n",
    "        self._target_table = table\n",
    "        self._targetdb = DBUtil(self.engine, schema)\n",
    "        return self\n",
    "\n",
    "    # Merge INTO ON ...\n",
    "    # if columns is None then use target check primarykeys\n",
    "    def on(self, on_columns: list[str] | None = None):\n",
    "        if on_columns is not None:\n",
    "            self._on_columns = on_columns\n",
    "\n",
    "        if self._targetdb is None or self._target_table is None:\n",
    "            raise Exception(\"target table not set\")\n",
    "        self._on_columns: list[str] = self._targetdb.get_primarykeys(self._target_table)\n",
    "        return self\n",
    "\n",
    "    def insert(self, insert_columns: Optional[List[str]] = None):\n",
    "        if insert_columns is not None:\n",
    "            self._insert_columns = insert_columns\n",
    "\n",
    "        if self._targetdb is None or self._target_table is None:\n",
    "            raise Exception(\"target table not set\")\n",
    "        tgt_cols: list[str] = self._targetdb.get_column_names(self._target_table)\n",
    "        src_cols: list[str] = self.get_column_names(self._source_table)\n",
    "        cols: list[str] = [c for c in src_cols if c in tgt_cols]\n",
    "        self._insert_columns = cols\n",
    "        return self\n",
    "\n",
    "    def update(self, update_columns:  Optional[List[str]] = None):\n",
    "        \n",
    "        if update_columns is not None:\n",
    "            self._update_columns = update_columns\n",
    "\n",
    "        if len(self._on_columns) == 0:\n",
    "            self.on()\n",
    "        if self._targetdb is None or self._target_table is None:\n",
    "            raise Exception(\"target table not set\")\n",
    "        tgt_cols: list[str] = self._targetdb.get_column_names(self._target_table)\n",
    "        src_cols: list[str] = self.get_column_names(self._source_table)\n",
    "        cols: list[str] = [c for c in src_cols if c in tgt_cols and c not in self._on_columns]\n",
    "        self._update_columns = cols\n",
    "        return self\n",
    "\n",
    "    def get_sql(self, more_insert: Optional[Dict[str, str]] = None, more_update: Optional[Dict[str, str]] = None) -> str:\n",
    "        if self._targetdb is None or self._target_table is None:\n",
    "            raise Exception(\"target table not set\")\n",
    "        if len(self._on_columns) == 0:\n",
    "            self.on()\n",
    "        if len(self._insert_columns) == 0:\n",
    "            self.insert()\n",
    "        if len(self._update_columns) == 0:\n",
    "            self.update()\n",
    "        # target table alias name t\n",
    "        sql: str = f\"MERGE INTO {self._target_schema}.{self._target_table} t \\n\"\n",
    "\n",
    "        # source table alias name s\n",
    "        sql += f\"USING {self._source_schema}.{self._source_table} s ON \\n\"\n",
    "        sql += f\"({self._on_columns}) \\n\"\n",
    "\n",
    "        # UPDATE\n",
    "        update_set: str = \", \".join([f\"{a} = s.{a}\" for a in self._update_columns])\n",
    "        if more_update is not None:\n",
    "            update_set = update_set + \", \" + \", \".join([f\"{k} = {v}\" for k, v in more_update.items()])\n",
    "        sql += f\"WHEN MATCHED THEN UPDATE SET {update_set} \\n\"\n",
    "\n",
    "        # INSERT cols\n",
    "        insert_cols = \",\".join(self._insert_columns)\n",
    "        insert_values: str = \",\".join([f\"s.{a}\" for a in self._insert_columns])\n",
    "        if more_insert is not None:\n",
    "            insert_cols: str = insert_cols + \",\" + \",\".join(more_insert.keys())\n",
    "            insert_values = insert_values + \",\" + \",\".join(more_insert.values())\n",
    "        sql += f\"WHEN NOT MATCHED THEN INSERT ({insert_cols}) VALUES ({insert_values}) \\n\"\n",
    "        sql += \";\"\n",
    "        return sql\n",
    "\n",
    "    def merge(self, more_insert: Optional[Dict[str, str]] = None, more_update: Optional[Dict[str, str]] = None) -> Any:\n",
    "        self.check_connect()\n",
    "        sql: str = self.get_sql(more_insert, more_update)\n",
    "        cur = self._targetdb.execute(sql)\n",
    "        return cur.fetchone()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
